todo 1 wordcount
MapReduce入门，主要是熟系一下MR的执行流程和Key的选择

todo 2 Covid
MapReduce进阶，是对美国疫情进行一系列的分析，主要是熟系
MR中自定义 分组、排序、分区、序列化的操作

todo 3 自定义计数器
MapReduce计数器，能统计一些Map阶段或Reduce阶段的数据，能
直观的查看某个数据的次数，而且实现的是全局统计。

todo 4 MySQL
MapReduce中的一些数据库操作，实现了数据的导入，导出操作
并将两个类封装成了两个方法，结合起来实现了类Sqoop的操作
能进行本地数据库和集群上（node03）数据库 表的导入导出功能
Join操作是对两个表或者数据集进行关联操作

todo 5 Join
MapReduce中涉及多个数据集并需要进行关联操作时就需要用到join关联
join关联又分为：
map端join：（必须在集群Yarn模式下运行）
在map端进行join关联，核心技术就是需要用到<分布式缓存>机制
优点是：一般不需要reduceTask阶段也就没了繁琐的Shuffle阶段，效率高，避免资源消耗
并且在map端运行可以充分发挥map的优势，能根据数据量的大小自动调整mapTask的个数
提高并行度，充分发挥分布式计算的优势
reduce端join：
在reduce端进行关联，实现方式简单，通过编写Bean包作为Key让相应的条件进行关联on连接
缺点：并行度低,且有shuffle过程时间慢而且消耗资源大

todo 6 IO
MapReduce的调优， todo 修改数据文件类型 小文件合并
对文件进行处理：
将文件修改为别的类型，转化为序列文件（SequenceFile），小文件合并等处理

todo 7 Compress
MapReduce的调优，todo 压缩处理
压缩类型    压缩比例    压缩解压时间
Bzip2         140:40         100
Gzip          140:45         50
Lzo           140:65         9  //Lzop压缩文件支持split
Lz4           140:68         4
Snappy        140:70         12

推荐在Shuffle过程中使用<Lz4>进行压缩
Shuffle过程使用压缩可以减少网络传输带宽，降低IO读写的次数

在Reduce输出阶段进行压缩其实就是将输出文件以压缩格式输出能减少磁盘的消耗

todo 8 属性优化
1 开启Uber模式，可以对小文件进行优化
conf.set("mapreduce.job.ubertask.enable","true")

2 开启JVM重用，一个JVM使用多个MapTask
conf.set("mapreduce.job.jvm.numtasks","10")

3 开启重试机制，在遇到外部因素时多试几次
conf.set("mapreduce.map.maxattempts","4")
conf.set("mapreduce.reduce.maxattempts","4")

4 关闭推测执行，减少不必要的资源浪费
conf.set("mapreduce.map.speculative","false")
conf.set("mapreduce.reduce.speculative","false")

5 使用小文件合并优化
//设置输入类型为 CombineFileInputFormat 可以对输入的小文件进行合并优化
job.setInputFormatClass(CombineFileInputFormat.class);
//设置最大切片为4M
CombineFileInputFormat.setMaxInputSplitSize(job,4194304);

6 设置Shuffle阶段的属性：
1>减少spill溢写次数：
调整缓冲区大小：
conf.set("mapreduce.task.io.sort.mb","200")//设置环形缓冲区大小为200M
调整溢写率
conf.set("mapreduce.map.sort.spill.percent","0.9")//设置溢写率为90%
2>减少merge合并次数：
conf.set("mapreduce.task.io.sort.factor","15")//设置每15个小文件合并一次
